{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from processing_utils import vector_db\n",
    "from config import config_params\n",
    "from suggestion_engine import SuggestionEngine\n",
    "from processing_utils import resource_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Start the SuggestionEngine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = SuggestionEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the initial KB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populate KB with tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(config_params[\"path_tweets_raw\"])\n",
    "\n",
    "#tweet-specific pre-processing\n",
    "tweets = resource_preprocessing.tweet_date_range(tweets, 'created_at', [2014, 2022]) #tweets after 2014 and before 2022\n",
    "tweets = resource_preprocessing.tweet_shuffle(tweets, 1, 41) #shuffle tweets\n",
    "tweets = resource_preprocessing.rm_links_handles(tweets, 'text') #adds new column \"text_clean\" that contains the text without links and handles\n",
    "\n",
    "tweets_prepared_dir = os.path.dirname(config_params[\"path_tweets_raw\"]) + '/prepared'\n",
    "os.mkdir(tweets_prepared_dir)\n",
    "tweets.to_pickle(tweets_prepared_dir+'/tweets_prepared.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.create_db_collection(tweets_prepared_dir, 'id', 'text_clean', engine.qdrantdb_client, engine.tweet_collection_name, engine.search_embedder, cross_dataset_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Populate KB with abstracts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.create_db_collection(config_params[\"path_abstracts\"], 'corpusid', 'abstract', engine.qdrantdb_client, engine.abstract_collection_name, engine.search_embedder, cross_dataset_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Suggestion Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Feedback**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_pickle(\"\")\n",
    "\n",
    "#Apply feedback-specific preprocessing, if necessary.\n",
    "#tweets = resource_preprocessing.rm_links_handles(tweets, 'text')\n",
    "\n",
    "engine.load_feedback(tweets, 'id', 'text_clean', cross_dataset_preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process Weakness Identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_weakness_batch, weakness_cluster_batch = engine.weaknesses_identification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weakness Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakness_cluster_batch = engine.weaknesses_clustering(cluster_min_size=1, cluster_threshold=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search Query Generation for each Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_queries_batch = engine.cluster_query_generation(cluster_max_examples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improvement Suggestion Generation for each Cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_queries_batch, weakness_cluster_batch, feedback_weakness_batch = engine.cluster_suggestion_generation(limit_results_retrieve=10, limit_results_rerank=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Suggestions for each Tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_weakness_batch = engine.feedback_answer_generation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "klu_py311_ar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
