{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    import os\n",
    "    import json\n",
    "    import vector_db\n",
    "    import pandas as pd\n",
    "    import search_rerank\n",
    "    import query_generation\n",
    "    import answer_generation\n",
    "    from openai import OpenAI\n",
    "    import weakness_clustering\n",
    "    import suggestion_creation\n",
    "    import resource_preprocessing\n",
    "    import weakness_identification\n",
    "    import suggestion_postprocessing\n",
    "    from qdrant_client import QdrantClient\n",
    "    from googleapiclient.discovery import build\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sentence_transformers.cross_encoder import CrossEncoder\n",
    "    from grobid_client_python.grobid_client.grobid_client import GrobidClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **General Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tweets_raw = ''\n",
    "path_tweets_raw_shuffled = ''\n",
    "path_tweets_clean_shuffled = ''\n",
    "\n",
    "path_abstracts = ''\n",
    "\n",
    "path_suggestions = ''\n",
    "\n",
    "#Vector_db\n",
    "abstract_collection_name = 'abstract_collection'\n",
    "tweet_collection_name = 'tweet_collection'\n",
    "limit_results = 10\n",
    "limit_results_rerank = 10\n",
    "\n",
    "#Sentence_transformer models\n",
    "embedding_model = 'all-MiniLM-L6-v2'\n",
    "cluster_embedding_model = 'all-mpnet-base-v2'\n",
    "cross_encoder_model = 'ms-marco-MiniLM-L-6-v2'\n",
    "\n",
    "#OpenAI models\n",
    "generative_model = \"gpt-4-0125-preview\"\n",
    "cluster_embedder_gpt = \"text-embedding-3-large\"\n",
    "openai_api_key=\"\"\n",
    "\n",
    "#Semnatic Scholar\n",
    "x_api_key = ''\n",
    "\n",
    "#Google\n",
    "GOOGLE_CSE_ID = \"\"\n",
    "GOOGLE_API_KEY = \"\"\n",
    "service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
    "\n",
    "#Setup Models\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "openAI_client = OpenAI()\n",
    "embedder = SentenceTransformer(embedding_model, device=\"cuda\")\n",
    "cluster_embedder = SentenceTransformer(cluster_embedding_model, device=\"cuda\")\n",
    "cross_encoder = CrossEncoder(f\"cross-encoder/{cross_encoder_model}\", device=\"cuda\")\n",
    "\n",
    "qdrantdb_client = QdrantClient(host=\"localhost\", grpc_port=6334, prefer_grpc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROBID server is up and running\n"
     ]
    }
   ],
   "source": [
    "#Run Grobid\n",
    "\n",
    "client = GrobidClient(config_path=\"grobid_client_python/config.json\")\n",
    "GROBID_URL = 'http://localhost:8070'\n",
    "url_setting = '%s/api/processFulltextDocument' % GROBID_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Shuffle and clean tweet dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2014 #only tweets after this year\n",
    "end_year = 2022 #only tweets before this year\n",
    "\n",
    "#Create shuffled dataset with tweets > start_year and tweets < end_year\n",
    "resource_preprocessing.prepare_tweet_dataset(path_tweets_raw, path_tweets_raw_shuffled, start_year, end_year, 'id', 'text', 'created_at')\n",
    "\n",
    "#Clean tweet dataset\n",
    "resource_preprocessing.clean_tweets(path_tweets_raw_shuffled, path_tweets_clean_shuffled, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating the initial KB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create vector store with abstracts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Qdrant collection and upload abstracts\n",
    "vector_db.create_db(path_abstracts, True, 'corpusid', 'abstract', qdrantdb_client, abstract_collection_name, embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create vector store with tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Qdrant collection and upload tweets\n",
    "vector_db.create_db(path_tweets_clean_shuffled, False, 'id', 'text_clean', qdrantdb_client, tweet_collection_name, embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Suggestion Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Tweets (after shuffling and cleaning)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_json(\"/home/ubuntu/SuggestionGeneration/MTurk/Suggestion_Annotation/output_CX_suggestions_cleaned.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = resource_preprocessing.preprocessing(tweets, source_column, text_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process Weakness Identification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_weakness_batch, weakness_batch, number_excepts = weakness_identification.identify_weaknesses(tweets, openAI_client, generative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weakness Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SentenceTransformers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the identified weaknesses\n",
    "weakness_cluster_batch = weakness_clustering.get_clusters(weakness_batch, cluster_embedder, cluster_min_size = 1, cluster_threshold=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search Query Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_queries_batch = query_generation.get_search_queries(weakness_cluster_batch, openAI_client, generative_model, cluster_max_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Individual Improvement Suggestion Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_query_results = []\n",
    "improvement_suggestions = []\n",
    "\n",
    "for idx, query in enumerate(cluster_queries_batch['search_query'].to_list()):\n",
    "    query_results = search_rerank.retrieve(query, qdrantdb_client, tweet_collection_name, abstract_collection_name, embedder, url_setting, x_api_key, service, GOOGLE_CSE_ID, limit_results)\n",
    "    reranked_query_results.append(search_rerank.rerank(cross_encoder, query, query_results, limit_results_rerank))\n",
    "    improvement_suggestions.append(suggestion_creation.get_suggestions(query, reranked_query_results[idx], openAI_client, generative_model))\n",
    "\n",
    "cluster_queries_batch['suggestions'] = improvement_suggestions\n",
    "cluster_queries_batch['reranked'] = reranked_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add suggestions to tweets\n",
    "weakness_cluster_batch, cluster_queries_batch, tweet_weakness_batch = suggestion_postprocessing.postprocessing(weakness_cluster_batch, cluster_queries_batch, tweet_weakness_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging Suggestions for each Tweet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_weakness_batch[\"answer\"] = answer_generation.get_answer(tweet_weakness_batch, openAI_client, generative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Generations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_weakness_batch.to_pickle(\"\")\n",
    "cluster_queries_batch.to_pickle(\"\")\n",
    "weakness_cluster_batch.to_pickle(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "klu_py311_ar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
